{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, Input\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import losses, optimizers\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIGAN:\n",
    "    def __init__(self):\n",
    "        img_rows = 28\n",
    "        img_cols = 28\n",
    "        img_channels = 1\n",
    "        self.img_shape = (img_row, img_cols, img_channels)\n",
    "        self.latet_dim = 100\n",
    "        \n",
    "        # optimizer\n",
    "        optimizer = optimizers.Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999)\n",
    "        \n",
    "        # build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss = losses.binary_crossentropy, optimizer = optimizer, metrics = ['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.encoder = self.build_encoder()\n",
    "        \n",
    "        # The part of the bigan that trains the discriminator and encoder\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        # Generate image from sampled noise\n",
    "        z = Input(shape = (self.latet_dim, ))\n",
    "        img_ = self.generator(z)\n",
    "        \n",
    "        # encode image\n",
    "        img = Input(shape = self.img_shape)\n",
    "        z_ = self.encoder(img)\n",
    "        \n",
    "        # Latent -> img is fake, and img -> latent is valid\n",
    "        fake = self.discriminator([z, img_])\n",
    "        valid = self.discriminator([z_, img])\n",
    "        \n",
    "        self.bigan_generator = Model(inputs = [z, img], outputs = [fake, valid])\n",
    "        self.bigan_generator.compile(loss = [losses.binary_crossentropy, losses.binary_crossentropy], optimizer = optimizer)\n",
    "        \n",
    "    def build_encoder(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(self.latent_dim))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        z = model(img)\n",
    "\n",
    "        return Model(img, z)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        gen_img = model(z)\n",
    "\n",
    "        return Model(z, gen_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        z = Input(shape=(self.latent_dim, ))\n",
    "        img = Input(shape=self.img_shape)\n",
    "        d_in = concatenate([z, Flatten()(img)])\n",
    "\n",
    "        model = Dense(1024)(d_in)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.5)(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.5)(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha=0.2)(model)\n",
    "        model = Dropout(0.5)(model)\n",
    "        validity = Dense(1, activation=\"sigmoid\")(model)\n",
    "\n",
    "        return Model([z, img], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Sample noise and generate img\n",
    "            z = np.random.normal(size=(batch_size, self.latent_dim))\n",
    "            imgs_ = self.generator.predict(z)\n",
    "\n",
    "            # Select a random batch of images and encode\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            z_ = self.encoder.predict(imgs)\n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
